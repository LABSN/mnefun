{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funloc experiment\n",
    "\n",
    "The experiment was a simple audio/visual oddball detection task. One\n",
    "potential purpose would be e.g. functional localization of auditory and\n",
    "visual cortices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "`import` statements find the necessary or useful modules (_Python file with some functions or variables in it_), load and initialize them if necessary and\n",
    "define alias(es) in the local namespace for the scope where the statement occurs. Through the import system Python code in one module gains access to the code in another module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mnefun\n",
    "from score import score\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    # Use niprov as handler for events if it's installed\n",
    "    from niprov.mnefunsupport import handler\n",
    "except ImportError:\n",
    "    handler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provenance\n",
    "[Niprov](https://github.com/ilogue/niprov.git) is a python program that uses meta-data to create, store and publish provenance for brain imaging files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by defining the processing parameters relavent to the study using the `mnefun.params` class object. We gain access to the variables in `params` using the (dot) operator.\n",
    "\n",
    "*Note* `shift`+`tab` invokes module documentation in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = mnefun.Params(tmin=-0.2, tmax=0.5, t_adjust=-4e-3,\n",
    "                       n_jobs=6, bmin=-0.2, bmax=None,\n",
    "                       decim=5, proj_sfreq=200, filter_length='5s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above statement defines a variable `params` that is bound to `mnefun` as class object, inheriting all the attributes and methods associated with that class. To see the attributes of an object in Python you can do..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now params is initialized with variable arguments from above along with default arguments for all other variables defined relavent to MEG data preprocessing.\n",
    "- `tmin` & `tmax` _define epoching interval_\n",
    "- `t_adjust` _adjusts for delays in the event trigger in units ms_\n",
    "- `n_jobs` _defines number of CPU jobs to use during parallel operations_\n",
    "- `bmin` & `bmax` _define baseline interval such that (-0.2, None) translates to DC offset correction for the baseline interval during averaging_\n",
    "- `decim` _actors to downsample the data after filtering when epoching data_\n",
    "- `filter_length` _Filter length to use in FIR filtering_\n",
    "- `proj_sfreq` _The sample freq to use for calculating projectors. Useful since\n",
    "    time points are not independent following low-pass. Also saves\n",
    "    computation to downsample_\n",
    "\n",
    "*Note* To use NVIDIA parallel computing platform (CUDA) use `params.n_jobs_fir='CUDA'` and `params.n_jobs_resample='CUDA'` Requires working CUDA development applications and other dependencies. See mne-python installation [instructions](http://martinos.org/mne/stable/install_mne_python.html#optional-advanced-setup)\n",
    "for further information.\n",
    "Otherwise set n_jobs_xxx > 1 to speed up resampling and filtering operations by multi-core parallel processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define `list` variables that determine...\n",
    "- `subjects` _list of subject identifiers_\n",
    "- `structurals` _list identifers pointing to FreeSurfer subject directory containing MRI data. Here `None` means missing MRI data, thus inversion operation is done using spherical head model with best-fit sphere aligned with subject's head shape_\n",
    "- `dates` _list of `None` or arbitrary date values as `tuple` type used for anonymizing subject's data_\n",
    "\n",
    "**All `list` variables in `params` have a one-to-one correspondence and are used for indexing purposes, thus\n",
    "assertion statements are used to check e.g. list lengths are equal.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params.subjects = ['subj_01', 'subj_02']\n",
    "params.structurals = [None, 'AKCLEE_110_slim']  # None means use sphere\n",
    "params.dates = [(2014, 2, 14), None]  # Use \"None\" to more fully anonymize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params.subject_indices = [0]  # Define which subjects to run\n",
    "params.plot_drop_logs = True  # Turn off so plots do not halt processing\n",
    "params.on_process = handler # Set the niprov handler to deal with events:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remote connections\n",
    "Set parameters for remotely connecting to acquisition **minea.ilabs.uw.edu** and Neuromag processing **kasga.ilabs.uw.edu** machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params.acq_ssh = 'kambiz@minea.ilabs.uw.edu'  # Should also be \"you@minea.ilabs.uw.edu\"\n",
    "# Pass list of paths to search and fetch raw data\n",
    "params.acq_dir = ['/sinuhe_data01/eric_non_space',\n",
    "                  '/data101/eric_non_space',\n",
    "                  '/sinuhe/data01/eric_non_space',\n",
    "                  '/sinuhe/data02/eric_non_space',\n",
    "                  '/sinuhe/data03/eric_non_space']\n",
    "\n",
    "# Set parameters for remotely connecting to SSS workstation ('sws')\n",
    "params.sws_ssh = 'kam@kasga.ilabs.uw.edu'  # Should also be \"you@kasga.ilabs.uw.edu\"\n",
    "params.sws_dir = '/data07/kam/sandbox'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File names\n",
    "Next we define:\n",
    "- `run_names` _tring identifier used in naming acquisition runs e.g., `'%s_funloc'` means {**str_funloc**} where str prefix is the subject ID_\n",
    "- `get_projs_from` _number of acquisition runs to use to build SSP projections for filtered data_\n",
    "- `inv_names` _prefix string to append to inverse operator file(s)_\n",
    "- `inv_runs` _number of acquisition runs to use to build inverse operator for filtered data_\n",
    "- `cov_method` _covariance calculation method_\n",
    "- `runs_empty` _name format of empty room recordings if any_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params.run_names = ['%s_funloc']\n",
    "params.get_projs_from = np.arange(1)\n",
    "params.inv_names = ['%s']\n",
    "params.inv_runs = [np.arange(1)]\n",
    "params.cov_method = 'shrunk'  # Cleaner noise covariance regularization\n",
    "params.runs_empty = ['%s_erm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial rejection criteria\n",
    "\n",
    "Use `reject` and `flat` dictionaries to pass noisy channel criteria to `mne.Epochs` during the epoching procedure. The noisy channel criteria are used to reject trials in which any gradiometer, magnetometer, or eeg channel exceeds the given criterion for that channel type, or is flat during the epoching interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params.reject = dict(grad=3500e-13, mag=4000e-15)\n",
    "params.flat = dict(grad=1e-13, mag=1e-15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Projections\n",
    "Here we define number of SSP projectors as a list of lists. The individual lists are used to define PCA projections computed for the electric signature from the heart and eyes, and also the ERM noise. Each projections list is a 1-by-3 row vector with columns corresponding to the number of PCA components for Grad/Mag/EEG channel types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params.proj_nums = [[1, 1, 0],  # ECG\n",
    "                    [1, 1, 2],  # EOG\n",
    "                    [0, 0, 0]]  # Continuous (from ERM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSS Denoising\n",
    "Next we set up for the SSS filtering method to use either Maxfilter or MNE. Regardless of the argument, in MNEFUN we use default Maxfilter parameter values for SSS. Users should consult the Maxfilter manual or see `mne.preprocessing.maxwell_filter` for more information on argument values; with the minimal invoke below the default Maxfilter arguments for SSS & tSSS, along with movement compensation is executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params.sss_type = 'python'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommended SSS denoising arguments for data from children:\n",
    "\n",
    "- `sss_regularize` = 'svd'    _# SSS basis regularization type_\n",
    "- `tsss_dur` = 4.             _# Buffer duration (in seconds) for spatiotemporal SSS/tSSS_\n",
    "- `int_order` = 6             _# Order of internal component of spherical expansion_\n",
    "- `st_correlation` = .9       _# Correlation limit between inner and outer SSS subspaces_\n",
    "- `trans_to` = (0, 0, .03)    _# The destination location for the head_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params.score = score  # Scoring function used to slice data into trials\n",
    "#  The scoring function needs to produce an event file with these values\n",
    "params.in_numbers = [10, 11, 20, 21]\n",
    "# Those values correspond to real categories as:\n",
    "params.in_names = ['Auditory/Standard', 'Visual/Standard',\n",
    "                   'Auditory/Deviant', 'Visual/Deviant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring function for MNEFUN example data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a scoring function i.e., score.py file exists then it must be imported and bound to `params.score` in order to handle trigger events in the `.fif` file as desired. The scoring function is used to extract trials from the filtered data. Typically the scoring function uses `mne.find_events` or `mnefun.extract_expyfun_events` to find events on the trigger line(s) in the raw `.fif` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Copyright (c) 2014, LABS^N\n",
    "# Distributed under the (new) BSD License. See LICENSE.txt for more info.\n",
    "\"\"\"\n",
    "----------------\n",
    "Score experiment\n",
    "----------------\n",
    "\n",
    "This sample scoring script shows how to convert the serial binary stamping\n",
    "from expyfun into meaningful event numbers using mnefun, and then write\n",
    "out the data to the location mnefun expects.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from os import path as op\n",
    "import mne\n",
    "from mnefun import extract_expyfun_events\n",
    "\n",
    "\n",
    "# Original coding used 8XX8 to code event types, here we translate to\n",
    "# a nicer decimal scheme\n",
    "_expyfun_dict = {\n",
    "    10: 10,  # 8448  (9) + 1 = 10: auditory std, recode as 10\n",
    "    12: 11,  # 8488 (11) + 1 = 12: visual std, recode as 11\n",
    "    14: 20,  # 8848 (13) + 1 = 14: auditory dev, recode as 20\n",
    "    16: 21,  # 8888 (15) + 1 = 16: visual dev, recode as 21\n",
    "}\n",
    "\n",
    "\n",
    "def score(p, subjects):\n",
    "    \"\"\"Scoring function\"\"\"\n",
    "    for subj in subjects:\n",
    "        print('  Running subject %s... ' % subj, end='')\n",
    "\n",
    "        # Figure out what our filenames should be\n",
    "        out_dir = op.join(p.work_dir, subj, p.list_dir)\n",
    "        if not op.isdir(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "\n",
    "        for run_name in p.run_names:\n",
    "            fname = op.join(p.work_dir, subj, p.raw_dir,\n",
    "                            (run_name % subj) + p.raw_fif_tag)\n",
    "            events, presses = extract_expyfun_events(fname)[:2]\n",
    "            for ii in range(len(events)):\n",
    "                events[ii, 2] = _expyfun_dict[events[ii, 2]]\n",
    "            fname_out = op.join(out_dir,\n",
    "                                'ALL_' + (run_name % subj) + '-eve.lst')\n",
    "            mne.write_events(fname_out, events)\n",
    "\n",
    "            # get subject performance\n",
    "            devs = (events[:, 2] % 2 == 1)\n",
    "            has_presses = np.array([len(pr) > 0 for pr in presses], bool)\n",
    "            n_devs = np.sum(devs)\n",
    "            hits = np.sum(has_presses[devs])\n",
    "            fas = np.sum(has_presses[~devs])\n",
    "            misses = n_devs - hits\n",
    "            crs = (len(devs) - n_devs) - fas\n",
    "            print('HMFC: %s, %s, %s, %s' % (hits, misses, fas, crs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define how to translate the above event types into evoked files\n",
    "params.analyses = [\n",
    "    'All',\n",
    "    'AV',\n",
    "]\n",
    "params.out_names = [\n",
    "    ['All'],\n",
    "    params.in_names,\n",
    "]\n",
    "params.out_numbers = [\n",
    "    [1, 1, 1, 1],       # Combine all trials\n",
    "    params.in_numbers,  # Leave events split the same way they were scored\n",
    "]\n",
    "params.must_match = [\n",
    "    [],\n",
    "    [0, 1],  # Only ensure the standard event counts match\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution\n",
    "Set what processing steps will execute..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnefun.do_processing(\n",
    "    params,\n",
    "    fetch_raw=True,     # Fetch raw recording files from acquisition machine\n",
    "    do_score=False,      # Do scoring to slice data into trials\n",
    "\n",
    "    \n",
    "    push_raw=False,      # Push raw files and SSS script to SSS workstation\n",
    "    do_sss=False,        # Run SSS remotely (on sws) or locally with mne-python\n",
    "    fetch_sss=False,     # Fetch SSSed files from SSS workstation\n",
    "    do_ch_fix=False,     # Fix channel ordering\n",
    "\n",
    "    gen_ssp=False,       # Generate SSP vectors\n",
    "    apply_ssp=False,     # Apply SSP vectors and filtering\n",
    "    plot_psd=False,      # Plot raw data power spectra\n",
    "    write_epochs=False,  # Write epochs to disk\n",
    "    gen_covs=False,      # Generate covariances\n",
    "\n",
    "    gen_fwd=False,       # Generate forward solutions (and src space if needed)\n",
    "    gen_inv=False,       # Generate inverses\n",
    "    gen_report=False,    # Write mne report html of results to disk\n",
    "    print_status=True,  # Print completeness status update\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
